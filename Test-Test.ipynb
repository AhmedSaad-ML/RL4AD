{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMain program implementing reinforcement learning for anomaly detection in KDD NSL Dataset\\nAuthor @hari.koduvely\\nDate Jan 2018\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main program implementing reinforcement learning for anomaly detection in KDD NSL Dataset\n",
    "Author @hari.koduvely\n",
    "Date Jan 2018\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-25 15:08:48,964] Making new env: NetworkIntrusion-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('NetworkIntrusion-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Specify the NN Architecture\n",
    "n_inputs = 226 # == env.observation_space.shape[0]\n",
    "n_hidden = 10\n",
    "n_outputs = 1 # prob of accelerating left\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "# 2. Build the NN\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "hidden = fully_connected(X, n_hidden, activation_fn=tf.nn.elu, weights_initializer=initializer)\n",
    "logits = fully_connected(hidden, n_outputs, activation_fn=None, weights_initializer=initializer)\n",
    "outputs = tf.nn.sigmoid(logits)\n",
    "\n",
    "#3. Select a random action based on the estimated probabilities\n",
    "p_yes_and_no = tf.concat(values=[outputs, 1 - outputs], axis=1)\n",
    "action = tf.multinomial(tf.log(p_yes_and_no), num_samples=1)\n",
    "\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up the training of the NN Using Policy Gradient\n",
    "\n",
    "y = 1.0 - tf.to_float(action) # target probability is 1 when action is 0 and 0 when action is 1\n",
    "learning_rate = 0.01\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(cross_entropy)\n",
    "gradients = [grad for grad, variable in grads_and_vars]\n",
    "gradient_placeholders = []\n",
    "grads_and_vars_feed = []\n",
    "for grad, variable in grads_and_vars:\n",
    "    gradient_placeholder = tf.placeholder(tf.float32)\n",
    "    gradient_placeholders.append(gradient_placeholder)\n",
    "    grads_and_vars_feed.append((gradient_placeholder, variable))\n",
    "    \n",
    "training_op = optimizer.apply_gradients(grads_and_vars_feed)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#Function to compute the total discounted rewards given the raw rewards\n",
    "def discount_rewards(rewards, discount_rate):\n",
    "    discounted_rewards = np.empty(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step] + discount_rate * cumulative_rewards\n",
    "        discounted_rewards[step] = cumulative_rewards\n",
    "    return discounted_rewards\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_rate) for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean)/reward_std for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n_iterations = 250 # number of training iterations\n",
    "n_max_steps = 1000 # max steps per episode\n",
    "n_games_per_update = 10 # train the policy every 10 episodes\n",
    "save_iterations = 10 # save the model every 10 training iterations\n",
    "discount_rate = 0.95\n",
    "\"\"\"\n",
    "n_iterations = 10 # number of training iterations\n",
    "n_max_steps = 100 # max steps per episode\n",
    "n_games_per_update = 10 # train the policy every 10 episodes\n",
    "save_iterations = 10 # save the model every 10 training iterations\n",
    "discount_rate = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Time: 411.271097898Secs\n"
     ]
    }
   ],
   "source": [
    "# Executing the graph\n",
    "t_start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        all_rewards = [] # all sequences of raw rewards for each episode\n",
    "        all_gradients = [] # gradients saved at each step of each episode\n",
    "        for game in range(n_games_per_update):\n",
    "            current_rewards = [] # all raw rewards for the current episode\n",
    "            current_gradients = [] # all gradients from the current episode\n",
    "            obs = env.reset()\n",
    "            for step in range(n_max_steps):\n",
    "                action_val, gradients_val = sess.run([action, gradients], feed_dict={X: np.array(list(obs)).reshape(1, n_inputs)})\n",
    "                obs, reward, done, info = env.step(action_val[0][0])\n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "                if done:\n",
    "                    break\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "            \n",
    "            # Perform a Policy Update after running the policy for 10 episodes\n",
    "            all_rewards = discount_and_normalize_rewards(all_rewards, discount_rate)\n",
    "            feed_dict = {}\n",
    "            for var_index, grad_placeholder in enumerate(gradient_placeholders):\n",
    "                # Multiply the gradients by the action scores and compute the mean\n",
    "                mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index]\n",
    "                                         for game_index, rewards in enumerate(all_rewards)\n",
    "                                         for step, reward in enumerate(rewards)], axis=0)\n",
    "                feed_dict[grad_placeholder] = mean_gradients\n",
    "                \n",
    "            sess.run(training_op, feed_dict=feed_dict)\n",
    "            if iteration % save_iterations == 0:\n",
    "                save_path = saver.save(sess, '/Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_CKPT/nsl_kdd_qlearning_3.ckpt')\n",
    "t_end = time.time()\n",
    "print(\"Traning Time: \" + str(t_end - t_start) + \"Secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_CKPT/nsl_kdd_qlearning_3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-25 16:40:58,419] Restoring parameters from /Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_CKPT/nsl_kdd_qlearning_3.ckpt\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c771897b1f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Saving the dataframe to a pickle file in directory DataSets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdf_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_PKL/kdd_nsl_train_results.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"precision: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "# Evaluation of the results\n",
    "n_max_steps = 1000\n",
    "o_list = []\n",
    "p_list = []\n",
    "a_list = []\n",
    "y_list = []\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'/Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_CKPT/nsl_kdd_qlearning_3.ckpt')\n",
    "    # load test dataset into a Pandas DataFrame\n",
    "    df = pd.read_pickle('/Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_PKL/kdd_nsl_train_onehot_string.pkl')\n",
    "    init.run()\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for step in range(n_max_steps):\n",
    "        obs = df.iloc[step]['s']\n",
    "        y = df.iloc[step]['y']\n",
    "        outputs = logits.eval(feed_dict={X: np.array(list(obs)).reshape(1, n_inputs)})\n",
    "        p_yes_and_no = tf.concat(values=[outputs, 1 - outputs], axis=1)\n",
    "        py = p_yes_and_no.eval()\n",
    "        action = tf.multinomial(tf.log(p_yes_and_no), num_samples=1)\n",
    "        act = action.eval()\n",
    "        o_list.append(obs)\n",
    "        p_list.append(py[0][0])\n",
    "        a_list.append(act[0][0])\n",
    "        y_list.append(y) \n",
    "        \n",
    "    df_pred = pd.DataFrame({'obs':o_list,'pred':p_list, 'action':a_list, 'y':y_list})\n",
    "    # Saving the dataframe to a pickle file in directory DataSets\n",
    "    df_pred.to_pickle('/Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_PKL/kdd_nsl_train_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>obs</th>\n",
       "      <th>pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tensor(\"multinomial_2001/Multinomial:0\", shape...</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.038880</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tensor(\"multinomial_2002/Multinomial:0\", shape...</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>-0.413541</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tensor(\"multinomial_2003/Multinomial:0\", shape...</td>\n",
       "      <td>1000010001001110001000010010010000110000101000...</td>\n",
       "      <td>0.135338</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tensor(\"multinomial_2004/Multinomial:0\", shape...</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.276748</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tensor(\"multinomial_2005/Multinomial:0\", shape...</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              action  \\\n",
       "0  Tensor(\"multinomial_2001/Multinomial:0\", shape...   \n",
       "1  Tensor(\"multinomial_2002/Multinomial:0\", shape...   \n",
       "2  Tensor(\"multinomial_2003/Multinomial:0\", shape...   \n",
       "3  Tensor(\"multinomial_2004/Multinomial:0\", shape...   \n",
       "4  Tensor(\"multinomial_2005/Multinomial:0\", shape...   \n",
       "\n",
       "                                                 obs      pred    y  \n",
       "0  1000010001001110001000010010010000110000110000...  0.038880 -1.0  \n",
       "1  1000010001001110001000010010010000110000110000... -0.413541 -1.0  \n",
       "2  1000010001001110001000010010010000110000101000...  0.135338  1.0  \n",
       "3  1000010001001110001000010010010000110000110000...  0.276748 -1.0  \n",
       "4  1000010001001110001000010010010000110000110000...  0.488189 -1.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pred = pd.read_pickle('/Users/harikoduvely/Projects/RL/DataSets/NSL_KDD_PKL/kdd_nsl_train_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>obs</th>\n",
       "      <th>pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.916389</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.803338</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000101000...</td>\n",
       "      <td>1.705354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.933582</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>1.254855</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1000010001001110001000010010010000110000101000...</td>\n",
       "      <td>0.809073</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000101000...</td>\n",
       "      <td>1.705354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000101000...</td>\n",
       "      <td>1.705354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000100100...</td>\n",
       "      <td>1.543989</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000101000...</td>\n",
       "      <td>1.705354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000100100...</td>\n",
       "      <td>0.751668</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000101000...</td>\n",
       "      <td>1.705354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>1.175340</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.896472</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000100100...</td>\n",
       "      <td>1.303137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>1.805340</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>1.178953</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>1.143817</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010001001110001000010010010000110000110000...</td>\n",
       "      <td>1.121368</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    action                                                obs      pred    y\n",
       "0        0  1000010001001110001000010010010000110000110000...  0.916389 -1.0\n",
       "1        0  1000010001001110001000010010010000110000110000...  0.803338 -1.0\n",
       "2        0  1000010001001110001000010010010000110000101000...  1.705354  1.0\n",
       "3        0  1000010001001110001000010010010000110000110000...  0.933582 -1.0\n",
       "4        0  1000010001001110001000010010010000110000110000...  1.254855 -1.0\n",
       "5        1  1000010001001110001000010010010000110000101000...  0.809073  1.0\n",
       "6        0  1000010001001110001000010010010000110000101000...  1.705354  1.0\n",
       "7        0  1000010001001110001000010010010000110000101000...  1.705354  1.0\n",
       "8        0  1000010001001110001000010010010000110000100100...  1.543989  1.0\n",
       "9        0  1000010001001110001000010010010000110000101000...  1.705354  1.0\n",
       "10       0  1000010001001110001000010010010000110000100100...  0.751668  1.0\n",
       "11       0  1000010001001110001000010010010000110000101000...  1.705354  1.0\n",
       "12       0  1000010001001110001000010010010000110000110000...  1.175340 -1.0\n",
       "13       0  1000010001001110001000010010010000110000110000...  0.896472  1.0\n",
       "14       0  1000010001001110001000010010010000110000100100...  1.303137  1.0\n",
       "15       0  1000010001001110001000010010010000110000110000...  1.805340  1.0\n",
       "16       0  1000010001001110001000010010010000110000110000...  1.178953 -1.0\n",
       "17       0  1000010001001110001000010010010000110000110000...  0.779732  1.0\n",
       "18       0  1000010001001110001000010010010000110000110000...  1.143817 -1.0\n",
       "19       0  1000010001001110001000010010010000110000110000...  1.121368 -1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    903\n",
       "1     97\n",
       "Name: action, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lam = 0.1 * np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_roc(df):\n",
    "    lamda = 0.1 * np.arange(10)\n",
    "    tpl = []\n",
    "    fpl = []\n",
    "    tnl = []\n",
    "    fnl = []\n",
    "    prl = []\n",
    "    rel = []\n",
    "    frl = []\n",
    "    for lam in lamda:\n",
    "        tp = 0.0\n",
    "        fp = 0.0\n",
    "        tn = 0.0\n",
    "        fn = 0.0\n",
    "        for i in range(df.shape[0]):\n",
    "            p = df.iloc[i]['pred']\n",
    "            y = df.iloc[i]['y']\n",
    "            y = y.astype(int)\n",
    "            if  y==1 and p>=lam:\n",
    "                tp += 1.0\n",
    "            elif y==1 and p<lam:\n",
    "                fn += 1.0\n",
    "            elif y==-1 and p>=lam:\n",
    "                fp += 1.0\n",
    "            elif y==-1 and p<lam:\n",
    "                tn += 1.0\n",
    "        pr = tp/(tp + fp + 1.0)\n",
    "        re = tp/(tp + fn + 1.0)\n",
    "        fr = fp/(tp + fp + 1.0)\n",
    "        tpl.append(tp)\n",
    "        fpl.append(fp)\n",
    "        tnl.append(tn)\n",
    "        fnl.append(fn)\n",
    "        prl.append(pr)\n",
    "        rel.append(re)\n",
    "        frl.append(fr)\n",
    "    df_lam = pd.DataFrame({'lam': lamda, 'TP': tpl, 'FP': fpl, 'TN': tnl, 'FN': fnl, 'Precision': prl, 'Recall': rel, 'FPR':frl})\n",
    "    return df_lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_in = df_pred.drop(['action','obs'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_lam = generate_roc(df_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>lam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.995876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.995876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>0.516032</td>\n",
       "      <td>0.482966</td>\n",
       "      <td>0.993814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.518145</td>\n",
       "      <td>0.480847</td>\n",
       "      <td>0.983505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.521516</td>\n",
       "      <td>0.477459</td>\n",
       "      <td>0.960825</td>\n",
       "      <td>7.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.517820</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.946392</td>\n",
       "      <td>22.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.520174</td>\n",
       "      <td>0.478735</td>\n",
       "      <td>0.905155</td>\n",
       "      <td>39.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>82.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.528103</td>\n",
       "      <td>0.470726</td>\n",
       "      <td>0.828866</td>\n",
       "      <td>65.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>0.524778</td>\n",
       "      <td>0.473952</td>\n",
       "      <td>0.769072</td>\n",
       "      <td>103.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>149.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.526761</td>\n",
       "      <td>0.471831</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>142.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FN     FP       FPR  Precision    Recall     TN     TP  lam\n",
       "0    1.0  516.0  0.516000   0.483000  0.995876    0.0  483.0  0.0\n",
       "1    1.0  516.0  0.516000   0.483000  0.995876    0.0  483.0  0.1\n",
       "2    2.0  515.0  0.516032   0.482966  0.993814    1.0  482.0  0.2\n",
       "3    7.0  514.0  0.518145   0.480847  0.983505    2.0  477.0  0.3\n",
       "4   18.0  509.0  0.521516   0.477459  0.960825    7.0  466.0  0.4\n",
       "5   25.0  494.0  0.517820   0.481132  0.946392   22.0  459.0  0.5\n",
       "6   45.0  477.0  0.520174   0.478735  0.905155   39.0  439.0  0.6\n",
       "7   82.0  451.0  0.528103   0.470726  0.828866   65.0  402.0  0.7\n",
       "8  111.0  413.0  0.524778   0.473952  0.769072  103.0  373.0  0.8\n",
       "9  149.0  374.0  0.526761   0.471831  0.690722  142.0  335.0  0.9"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lam.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13fe044d0>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(df_lam['FPR'],df_lam['Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv4hInPn/ELT9zuzkkGUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13fce0b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
